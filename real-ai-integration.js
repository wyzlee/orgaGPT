// real-ai-integration.js - Int√©gration de vraies IA pour OrgaGPT

class RealAIOrgaGPT {
    constructor(app) {
        this.app = app;
        this.aiProviders = {
            openai: null,
            huggingface: null,
            cohere: null,
            localLLM: null
        };
        
        // Configuration des diff√©rentes options IA
        this.config = {
            // Option 1: OpenAI (payant mais tr√®s performant)
            openai: {
                apiKey: '', // √Ä remplir
                model: 'gpt-3.5-turbo',
                endpoint: 'https://api.openai.com/v1/chat/completions'
            },
            
            // Option 2: Hugging Face (gratuit avec limitations)
            huggingface: {
                apiKey: '', // Gratuit sur huggingface.co
                model: 'microsoft/DialoGPT-medium',
                endpoint: 'https://api-inference.huggingface.co/models/'
            },
            
            // Option 3: Cohere (freemium - 100 requ√™tes/min gratuit)
            cohere: {
                apiKey: '', // Gratuit sur cohere.ai
                endpoint: 'https://api.cohere.ai/v1/generate'
            },
            
            // Option 4: Ollama (100% local et gratuit)
            ollama: {
                endpoint: 'http://localhost:11434/api/generate',
                model: 'mistral' // Mod√®le Mistral configur√© par l'utilisateur
            },
            
            // Option 5: Google Gemini (gratuit avec limitations)
            gemini: {
                apiKey: '', // Gratuit sur makersuite.google.com
                endpoint: 'https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent'
            }
        };
        
        this.initAI();
    }

    async initAI() {
        console.log('üöÄ Initialisation de RealAIOrgaGPT...');
        
        // D√©sactiver les autres int√©grations IA pour √©viter les conflits
        this.disableOtherAIIntegrations();
        
        // D√©tecter quelle option IA utiliser
        await this.detectAvailableAI();
        
        // Remplacer la m√©thode de chat de l'app originale
        const replaced = this.replaceAppChatMethod();
        
        if (!replaced) {
            console.error('‚ùå Impossible d\'initialiser RealAIOrgaGPT: √©chec du remplacement de sendChatMessage');
            return;
        }
        
        // Ajouter le s√©lecteur d'IA dans l'interface
        this.addAISelector();
        
        // Ajouter des styles pour le Markdown
        this.addMarkdownStyles();
        
        // Notifier l'utilisateur que l'IA est active
        this.notifyAIActive();
        
        console.log('‚úÖ RealAIOrgaGPT initialis√© avec succ√®s!');
    }
    
    /**
     * D√©sactive les autres int√©grations IA pour √©viter les conflits
     */
    disableOtherAIIntegrations() {
        // V√©rifier si EnhancedOrgaGPT est pr√©sent et le d√©sactiver
        if (window.enhancedApp) {
            console.log('üö® D√©tection de EnhancedOrgaGPT, d√©sactivation...');
            try {
                // Sauvegarder la base de connaissances si elle existe
                if (window.enhancedApp.api && window.enhancedApp.api.knowledgeBase) {
                    this.knowledgeBase = window.enhancedApp.api.knowledgeBase;
                    console.log('üìñ Base de connaissances r√©cup√©r√©e depuis EnhancedOrgaGPT');
                }
                
                // D√©sactiver en remettant la m√©thode originale
                if (window.enhancedApp.app && window.enhancedApp.originalSendChatMessage) {
                    window.enhancedApp.app.sendChatMessage = window.enhancedApp.originalSendChatMessage;
                    console.log('‚úÖ M√©thode sendChatMessage d\'EnhancedOrgaGPT d√©sactiv√©e');
                }
            } catch (e) {
                console.error('Erreur lors de la d√©sactivation d\'EnhancedOrgaGPT:', e);
            }
        }
        
        // V√©rifier si des styles d'Ollama sont d√©j√† pr√©sents (signe que ollama-service.js est actif)
        const ollamaStyles = document.querySelector('style[data-source="ollama-service"]');
        if (ollamaStyles) {
            console.log('üö® D√©tection de ollama-service.js, d√©sactivation...');
            // Ne pas supprimer les styles car ils peuvent √™tre utiles
            // Mais r√©tablir la m√©thode originale si possible
            if (window.orgaGPT && window.orgaGPT._originalSendChatMessage) {
                window.orgaGPT.sendChatMessage = window.orgaGPT._originalSendChatMessage;
                console.log('‚úÖ M√©thode sendChatMessage d\'ollama-service.js d√©sactiv√©e');
            }
        }
        
        console.log('üîß Environnement pr√©par√© pour RealAIOrgaGPT');
    }
    
    /**
     * Ajoute des styles CSS pour am√©liorer l'affichage du Markdown
     */
    addMarkdownStyles() {
        const markdownStyles = `
        <style>
            /* Styles pour le rendu Markdown dans le chat */
            .ai-message h1, .ai-message h2, .ai-message h3, .ai-message h4 {
                margin-top: 0.5em;
                margin-bottom: 0.5em;
                font-weight: bold;
                color: #333;
            }
            
            .ai-message h1 { font-size: 1.5em; }
            .ai-message h2 { font-size: 1.3em; }
            .ai-message h3 { font-size: 1.2em; }
            .ai-message h4 { font-size: 1.1em; }
            
            .ai-message p {
                margin-bottom: 0.8em;
            }
            
            .ai-message ul, .ai-message ol {
                margin-left: 1.5em;
                margin-bottom: 0.8em;
            }
            
            .ai-message li {
                margin-bottom: 0.3em;
            }
            
            .ai-message code {
                background-color: rgba(0, 0, 0, 0.05);
                padding: 0.2em 0.4em;
                border-radius: 3px;
                font-family: monospace;
                font-size: 0.9em;
            }
            
            .ai-message pre {
                background-color: rgba(0, 0, 0, 0.05);
                padding: 0.8em;
                border-radius: 5px;
                overflow-x: auto;
                margin-bottom: 1em;
            }
            
            .ai-message pre code {
                background-color: transparent;
                padding: 0;
            }
            
            .ai-message blockquote {
                border-left: 3px solid #ccc;
                padding-left: 1em;
                margin-left: 0;
                color: #555;
                font-style: italic;
            }
            
            .ai-message table {
                border-collapse: collapse;
                width: 100%;
                margin-bottom: 1em;
            }
            
            .ai-message th, .ai-message td {
                border: 1px solid #ddd;
                padding: 0.5em;
                text-align: left;
            }
            
            .ai-message th {
                background-color: rgba(0, 0, 0, 0.05);
            }
            
            .ai-message a {
                color: #0366d6;
                text-decoration: none;
            }
            
            .ai-message a:hover {
                text-decoration: underline;
            }
            
            .ai-message img {
                max-width: 100%;
                height: auto;
            }
        </style>
        `;
        
        document.head.insertAdjacentHTML('beforeend', markdownStyles);
    }
    
    /**
     * Notifie l'utilisateur que l'IA est active
     */
    notifyAIActive() {
        // Ajouter un indicateur visuel dans l'interface
        const aiTitle = document.querySelector('.sidebar__section h3');
        if (aiTitle && aiTitle.textContent.includes('Copilote IA')) {
            aiTitle.innerHTML = 'ü§ñ Copilote IA <span style="color: green; font-size: 0.8em; background: rgba(0,255,0,0.1); padding: 2px 6px; border-radius: 10px;">‚úì IA ACTIVE</span>';
        }
        
        // Ajouter un message dans le chat
        const chatMessages = document.getElementById('chatMessages');
        if (chatMessages) {
            const statusMessage = document.createElement('div');
            statusMessage.className = 'ai-message system-message';
            statusMessage.innerHTML = DOMPurify.sanitize(marked.parse(`**Syst√®me:** IA ${this.ollamaAvailable ? 'Ollama' : 'locale'} activ√©e avec support **Markdown**. Posez vos questions et demandez-moi de g√©rer vos t√¢ches!`));
            chatMessages.appendChild(statusMessage);
            
            // Scroll to bottom
            setTimeout(() => {
                chatMessages.scrollTop = chatMessages.scrollHeight;
            }, 100);
        }
    }

    detectAvailableAI() {
        // V√©rifier les cl√©s API disponibles dans localStorage
        const savedConfig = localStorage.getItem('orgagpt-ai-config');
        if (savedConfig) {
            const config = JSON.parse(savedConfig);
            Object.assign(this.config, config);
        }
        
        // V√©rifier si Ollama est disponible localement
        this.checkOllama();
    }

    async checkOllama() {
        try {
            const response = await fetch('http://localhost:11434/api/tags');
            if (response.ok) {
                const data = await response.json();
                console.log('Ollama disponible avec les mod√®les:', data.models);
                this.ollamaAvailable = true;
                
                // V√©rifier si le mod√®le Mistral est disponible
                const models = data.models || [];
                const mistralAvailable = models.some(model => 
                    model.name === 'mistral' || model.name.includes('mistral'));
                
                if (!mistralAvailable) {
                    console.warn('Mod√®le Mistral non d√©tect√©. Pour l\'installer: ollama pull mistral');
                    // Afficher un message dans le chat
                    setTimeout(() => {
                        const chatMessages = document.getElementById('chatMessages');
                        if (chatMessages) {
                            const warningMessage = document.createElement('div');
                            warningMessage.className = 'ai-message system-message';
                            warningMessage.innerHTML = DOMPurify.sanitize(marked.parse(
                                '**Syst√®me:** Ollama est d√©tect√© mais le mod√®le Mistral n\'est pas install√©. ' +
                                'Pour l\'installer, ex√©cutez la commande suivante dans votre terminal:\n```\nollama pull mistral\n```'
                            ));
                            chatMessages.appendChild(warningMessage);
                        }
                    }, 1000);
                }
            }
        } catch (e) {
            console.log('Ollama non d√©tect√©. Installez-le depuis ollama.ai pour une IA locale gratuite.');
            this.ollamaAvailable = false;
            
            // Afficher un message dans le chat apr√®s un d√©lai
            setTimeout(() => {
                const chatMessages = document.getElementById('chatMessages');
                if (chatMessages) {
                    const errorMessage = document.createElement('div');
                    errorMessage.className = 'ai-message error-message';
                    errorMessage.innerHTML = DOMPurify.sanitize(marked.parse(
                        '**Syst√®me:** Ollama n\'est pas d√©tect√©. Assurez-vous qu\'il est install√© et en cours d\'ex√©cution.\n\n' +
                        '1. Installez Ollama depuis [ollama.ai](https://ollama.ai)\n' +
                        '2. Ex√©cutez `ollama serve` dans votre terminal\n' +
                        '3. Installez le mod√®le Mistral avec `ollama pull mistral`\n\n' +
                        'En attendant, je vais utiliser des r√©ponses locales.'
                    ));
                    chatMessages.appendChild(errorMessage);
                }
            }, 1000);
        }
    }

    replaceAppChatMethod() {
        if (!this.app || typeof this.app.sendChatMessage !== 'function') {
            console.error('‚ùå Impossible de remplacer sendChatMessage: m√©thode non trouv√©e ou app non initialis√©e');
            return false;
        }
        
        // Sauvegarder une r√©f√©rence √† la m√©thode originale pour le fallback
        this.originalSendChatMessage = this.app.sendChatMessage;
        console.log('üíæ M√©thode sendChatMessage originale sauvegard√©e pour fallback');
        
        // D√©finir la nouvelle m√©thode sendChatMessage
        const newMethod = async () => {
            const input = document.getElementById('chatInput');
            const message = input.value.trim();
            
            if (!message || !input) return;

            this.app.addUserMessage(message);
            input.value = '';

            // Cr√©er l'indicateur de chargement
            const chatMessages = document.getElementById('chatMessages');
            const loadingDiv = document.createElement('div');
            loadingDiv.className = 'ai-message typing-indicator';
            loadingDiv.innerHTML = '<span>.</span><span>.</span><span>.</span>';
            chatMessages.appendChild(loadingDiv);
            
            // Scroll to bottom
            chatMessages.scrollTop = chatMessages.scrollHeight;

            try {
                console.log('üîÑ Envoi de la requ√™te √† l\'IA...');
                
                // Obtenir une vraie r√©ponse IA
                const response = await this.getAIResponse(message);
                
                // Supprimer l'indicateur de chargement
                loadingDiv.remove();
                
                // Ajouter la r√©ponse de l'IA
                this.app.addAIMessage(response);
                console.log('‚úÖ R√©ponse IA re√ßue avec succ√®s!');
                
            } catch (error) {
                console.error('‚ùå Erreur IA:', error);
                
                // Supprimer l'indicateur de chargement
                loadingDiv.remove();
                
                // Message d'erreur
                const errorDiv = document.createElement('div');
                errorDiv.className = 'ai-message error-message';
                errorDiv.innerHTML = DOMPurify.sanitize(marked.parse('**Erreur de connexion √† l\'IA:** ' + error.message + '\n\nAssurez-vous qu\'Ollama est bien lanc√© avec:\n```\nollama serve\n```\n\nJe vais utiliser une r√©ponse locale en attendant.'));
                chatMessages.appendChild(errorDiv);
                
                // Fallback vers la m√©thode originale apr√®s un d√©lai
                setTimeout(() => {
                    try {
                        const fallbackResponse = this.getSmartFallback(message);
                        this.app.addAIMessage(fallbackResponse + '\n\n*[Note: R√©ponse g√©n√©r√©e localement]*');
                    } catch (fallbackError) {
                        console.error('Erreur dans le fallback:', fallbackError);
                        this.app.addAIMessage('D√©sol√©, je ne peux pas r√©pondre pour le moment. Veuillez r√©essayer plus tard.');
                    }
                }, 1000);
            }
        };
        
        // Remplacer la m√©thode
        try {
            // Utiliser Object.defineProperty pour √©viter les probl√®mes de remplacement
            Object.defineProperty(this.app, 'sendChatMessage', {
                value: newMethod,
                writable: true,
                configurable: true
            });
            
            console.log('‚úÖ M√©thode sendChatMessage remplac√©e avec succ√®s');
            return true;
        } catch (error) {
            console.error('‚ùå Erreur lors du remplacement de sendChatMessage:', error);
            return false;
        }
    }

    async getAIResponse(message) {
        // Enrichir le contexte
        const context = this.buildContext();
        const prompt = this.buildPrompt(message, context);
        
        // Essayer les diff√©rents providers dans l'ordre
        const providers = [
            () => this.tryOllama(prompt),
            () => this.tryHuggingFace(prompt),
            () => this.tryCohere(prompt),
            () => this.tryGemini(prompt),
            () => this.tryOpenAI(prompt)
        ];
        
        for (const provider of providers) {
            try {
                const rawResponse = await provider();
                if (rawResponse) {
                    // Extraire les actions et nettoyer la r√©ponse
                    const { cleanResponse, actions } = this.extractActionsAndCleanResponse(rawResponse);
                    
                    // Ex√©cuter les actions si pr√©sentes
                    if (actions.length > 0) {
                        this.executeAIActions(actions);
                    }
                    
                    return cleanResponse;
                }
            } catch (e) {
                console.log('Provider failed, trying next...', e);
            }
        }
        
        throw new Error('Aucun provider IA disponible');
    }
    
    /**
     * Extrait les actions du format [ACTION:{...}] et nettoie la r√©ponse
     * @param {string} responseText - R√©ponse brute de l'IA
     * @returns {Object} - {cleanResponse, actions}
     */
    extractActionsAndCleanResponse(responseText) {
        const actions = [];
        const actionRegex = /\[ACTION:(\{.*?\})\]/g;
        
        // Remplacer les actions par une cha√Æne vide pour nettoyer la r√©ponse
        const cleanResponse = responseText.replace(actionRegex, (fullMatch, actionJson) => {
            try {
                const actionData = JSON.parse(actionJson);
                actions.push(actionData);
                console.log('Action extraite:', actionData);
                return ''; // Supprime l'action du texte affich√©
            } catch (e) {
                console.error("Erreur de parsing de l'action JSON:", actionJson, e);
                return ''; // Supprime √©galement en cas d'erreur
            }
        }).trim();
        
        return { cleanResponse, actions };
    }
    
    /**
     * Ex√©cute une liste d'actions
     * @param {Array} actions - Liste des actions √† ex√©cuter
     */
    executeAIActions(actions) {
        actions.forEach(actionData => {
            console.log('Ex√©cution de l\'action:', actionData);
            
            try {
                switch (actionData.intent) {
                    case "create_task":
                        this.executeCreateTask(actionData.parameters);
                        break;
                        
                    case "complete_task":
                        this.executeCompleteTask(actionData.parameters);
                        break;
                        
                    case "list_tasks":
                        this.executeListTasks(actionData.parameters);
                        break;
                        
                    case "update_task":
                        this.executeUpdateTask(actionData.parameters);
                        break;
                        
                    default:
                        console.warn('Action non reconnue:', actionData.intent);
                }
            } catch (error) {
                console.error(`Erreur lors de l'ex√©cution de l'action ${actionData.intent}:`, error);
                this.app.addAIMessage(`‚ö†Ô∏è **Erreur:** Je n'ai pas pu ex√©cuter l'action ${actionData.intent}. ${error.message}`);
            }
        });
    }
    
    /**
     * Traite les actions contenues dans la r√©ponse de l'IA
     * Format: [ACTION:{"intent":"create_task","parameters":{...}}]
     * @deprecated Utilisez extractActionsAndCleanResponse et executeAIActions √† la place
     */
    processAIActions(response) {
        // V√©rifier si la r√©ponse contient une action
        if (response.includes("[ACTION:") && response.includes("]")) {
            try {
                // Utiliser la nouvelle m√©thode d'extraction
                const { actions } = this.extractActionsAndCleanResponse(response);
                
                // Ex√©cuter les actions extraites
                if (actions.length > 0) {
                    this.executeAIActions(actions);
                }
            } catch (error) {
                console.error('Erreur lors du traitement des actions:', error);
            }
        }
    }
    
    /**
     * Ex√©cute l'action de cr√©ation de t√¢che
     */
    executeCreateTask(params) {
        if (!params.title) return;
        
        const taskData = {
            id: Date.now(),
            title: params.title,
            priority: params.priority || 'medium',
            estimatedTime: parseInt(params.estimatedTime) || 30,
            category: params.category || 'general',
            completed: false,
            quadrant: params.quadrant || 2
        };
        
        // Ajouter la t√¢che
        this.app.tasks.push(taskData);
        
        // Mettre √† jour l'interface
        this.app.updateTaskList();
        this.app.updateEisenhowerMatrix();
        
        // Notification
        this.app.addAIMessage(`‚úÖ J'ai cr√©√© la t√¢che **${taskData.title}** avec une priorit√© **${taskData.priority}** et un temps estim√© de **${taskData.estimatedTime} minutes**.`);
    }
    
    /**
     * Ex√©cute l'action de compl√©tion de t√¢che
     */
    executeCompleteTask(params) {
        if (!params.taskName) return;
        
        // Rechercher la t√¢che par son nom (recherche partielle insensible √† la casse)
        const taskToComplete = this.app.tasks.find(t => 
            t.title.toLowerCase().includes(params.taskName.toLowerCase()));
            
        if (taskToComplete) {
            // Marquer comme termin√©e
            taskToComplete.completed = true;
            
            // Mettre √† jour l'interface
            this.app.updateTaskList();
            this.app.updateEisenhowerMatrix();
            
            // Notification
            this.app.addAIMessage(`‚úÖ J'ai marqu√© la t√¢che **${taskToComplete.title}** comme termin√©e.`);
        } else {
            this.app.addAIMessage(`‚ùì Je n'ai pas trouv√© de t√¢che correspondant √† "${params.taskName}".`);
        }
    }
    
    /**
     * Ex√©cute l'action de listage des t√¢ches
     */
    executeListTasks(params) {
        // Filtrer les t√¢ches selon les param√®tres
        let filteredTasks = [...this.app.tasks];
        
        if (params.completed === true) {
            filteredTasks = filteredTasks.filter(t => t.completed);
        } else if (params.completed === false) {
            filteredTasks = filteredTasks.filter(t => !t.completed);
        }
        
        if (params.priority) {
            filteredTasks = filteredTasks.filter(t => t.priority === params.priority);
        }
        
        if (params.category) {
            filteredTasks = filteredTasks.filter(t => t.category === params.category);
        }
        
        // Formater la r√©ponse en Markdown
        let response = "";
        
        if (filteredTasks.length === 0) {
            response = "üìã Aucune t√¢che ne correspond √† ces crit√®res.";
        } else {
            response = "üìã **Voici les t√¢ches demand√©es:**\n\n";
            
            filteredTasks.forEach(task => {
                const status = task.completed ? "‚úÖ" : "‚¨ú";
                const priority = {
                    high: "üî¥",
                    medium: "üü†",
                    low: "üü¢"
                }[task.priority] || "‚ö™";
                
                response += `${status} **${task.title}** (${priority} ¬∑ ${task.estimatedTime}min ¬∑ ${task.category})\n`;
            });
        }
        
        this.app.addAIMessage(response);
    }
    
    /**
     * Ex√©cute l'action de mise √† jour de t√¢che
     */
    executeUpdateTask(params) {
        if (!params.taskName) return;
        
        // Rechercher la t√¢che par son nom
        const taskToUpdate = this.app.tasks.find(t => 
            t.title.toLowerCase().includes(params.taskName.toLowerCase()));
            
        if (taskToUpdate) {
            // Mettre √† jour les propri√©t√©s
            if (params.newTitle) taskToUpdate.title = params.newTitle;
            if (params.priority) taskToUpdate.priority = params.priority;
            if (params.estimatedTime) taskToUpdate.estimatedTime = parseInt(params.estimatedTime);
            if (params.category) taskToUpdate.category = params.category;
            if (params.quadrant) taskToUpdate.quadrant = parseInt(params.quadrant);
            
            // Mettre √† jour l'interface
            this.app.updateTaskList();
            this.app.updateEisenhowerMatrix();
            
            // Notification
            this.app.addAIMessage(`‚úÖ J'ai mis √† jour la t√¢che **${taskToUpdate.title}**.`);
        } else {
            this.app.addAIMessage(`‚ùì Je n'ai pas trouv√© de t√¢che correspondant √† "${params.taskName}".`);
        }
    }

    buildContext() {
        return {
            tasks: this.app.tasks,
            completedTasks: this.app.tasks.filter(t => t.completed).length,
            totalTasks: this.app.tasks.length,
            energyLevel: document.getElementById('energyLevel')?.value || 'medium',
            currentTime: new Date().toLocaleTimeString('fr-FR'),
            pomodoroCount: this.app.pomodoroCount,
            focusTime: Math.round(this.app.totalFocusTime / 60) + 'h',
            topPriorities: this.app.tasks
                .filter(t => t.priority === 'high' && !t.completed)
                .slice(0, 3)
                .map(t => t.title)
        };
    }

    buildPrompt(message, context) {
        return `Tu es OrgaGPT, un assistant de productivit√© expert bas√© sur les recherches de McKinsey, Deloitte, BCG et KPMG.

Contexte actuel de l'utilisateur:
- ${context.totalTasks} t√¢ches dont ${context.completedTasks} compl√©t√©es
- Niveau d'√©nergie: ${context.energyLevel}
- Temps de focus aujourd'hui: ${context.focusTime}
- Priorit√©s actuelles: ${context.topPriorities.join(', ') || 'Aucune priorit√© d√©finie'}
- Heure: ${context.currentTime}

Insights disponibles:
- McKinsey: "95% du temps sur les 5 priorit√©s principales"
- Deloitte: "31h/mois perdues en r√©unions improductives"
- BCG: "40-60% pr√©sentiel = √©quilibre optimal"
- KPMG: "Aligner t√¢ches complexes avec pics d'√©nergie"

=== CAPACIT√âS SP√âCIALES ===
Tu peux ex√©cuter des actions dans l'application en incluant ces commandes dans ta r√©ponse:

1. CR√âER UNE T√ÇCHE:
[ACTION:{"intent":"create_task","parameters":{"title":"Nom de la t√¢che","priority":"high/medium/low","estimatedTime":30,"category":"planning/creative/deep_work/communication"}}]

2. MARQUER UNE T√ÇCHE COMME TERMIN√âE:
[ACTION:{"intent":"complete_task","parameters":{"taskName":"Nom de la t√¢che"}}]

3. LISTER LES T√ÇCHES (avec filtres optionnels):
[ACTION:{"intent":"list_tasks","parameters":{"completed":true/false,"priority":"high/medium/low","category":"planning"}}]

4. METTRE √Ä JOUR UNE T√ÇCHE:
[ACTION:{"intent":"update_task","parameters":{"taskName":"Nom actuel","newTitle":"Nouveau nom","priority":"high","estimatedTime":45}}]

=== EXEMPLES D'UTILISATION DES ACTIONS ===

Exemple 1 - Cr√©ation de t√¢che:
Utilisateur: "Cr√©e une t√¢che pour pr√©parer la pr√©sentation marketing pour demain"
R√©ponse: "Je vais cr√©er cette t√¢che pour vous tout de suite.
[ACTION:{"intent":"create_task","parameters":{"title":"Pr√©parer la pr√©sentation marketing","priority":"high","estimatedTime":60,"category":"creative"}}]
Votre t√¢che a √©t√© cr√©√©e avec succ√®s! Voulez-vous que je vous aide √† planifier cette pr√©sentation?"

Exemple 2 - Listage des t√¢ches:
Utilisateur: "Montre-moi mes t√¢ches prioritaires"
R√©ponse: "Voici vos t√¢ches prioritaires :
[ACTION:{"intent":"list_tasks","parameters":{"priority":"high","completed":false}}]"

Exemple 3 - Compl√©tion de t√¢che:
Utilisateur: "J'ai termin√© la r√©union avec l'√©quipe marketing"
R√©ponse: "Super! Je vais marquer cette t√¢che comme termin√©e.
[ACTION:{"intent":"complete_task","parameters":{"taskName":"R√©union √©quipe marketing"}}]
Bravo pour cette t√¢che accomplie! Quelle est la prochaine √©tape?"

Exemple 4 - Mise √† jour de t√¢che:
Utilisateur: "Change la priorit√© de la t√¢che 'Finaliser le rapport' en haute priorit√©"
R√©ponse: "Je vais mettre √† jour cette t√¢che imm√©diatement.
[ACTION:{"intent":"update_task","parameters":{"taskName":"Finaliser le rapport","priority":"high"}}]
La priorit√© a √©t√© mise √† jour. Cette t√¢che est maintenant en haute priorit√©."

Question de l'utilisateur: ${message}

R√©ponds TOUJOURS en utilisant le format Markdown. Utilise des titres (##), des listes √† puces, du texte en **gras** et en *italique* pour structurer tes r√©ponses. Utilise des √©mojis pertinents et cite les sources entre crochets quand tu mentionnes des statistiques.

Si l'utilisateur te demande de cr√©er une t√¢che, de lister des t√¢ches ou de faire une action sur une t√¢che, utilise les commandes ACTION ci-dessus. Assure-toi que le format JSON est correct et que les guillemets sont bien √©chapp√©s.`;
    }

    // Option 1: Ollama (100% local et gratuit)
    async tryOllama(prompt) {
        if (!this.ollamaAvailable) return null;
        
        const response = await fetch(this.config.ollama.endpoint, {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({
                model: this.config.ollama.model,
                prompt: prompt,
                stream: false
            })
        });
        
        const data = await response.json();
        return data.response;
    }

    // Option 2: Hugging Face (gratuit avec limitations)
    async tryHuggingFace(prompt) {
        if (!this.config.huggingface.apiKey) return null;
        
        const response = await fetch(
            this.config.huggingface.endpoint + this.config.huggingface.model,
            {
                method: 'POST',
                headers: {
                    'Authorization': `Bearer ${this.config.huggingface.apiKey}`,
                    'Content-Type': 'application/json'
                },
                body: JSON.stringify({
                    inputs: prompt,
                    parameters: {
                        max_length: 200,
                        temperature: 0.7,
                        top_p: 0.9
                    }
                })
            }
        );
        
        const data = await response.json();
        return data[0]?.generated_text || data.generated_text;
    }

    // Option 3: Cohere (100 requ√™tes/min gratuit)
    async tryCohere(prompt) {
        if (!this.config.cohere.apiKey) return null;
        
        const response = await fetch(this.config.cohere.endpoint, {
            method: 'POST',
            headers: {
                'Authorization': `Bearer ${this.config.cohere.apiKey}`,
                'Content-Type': 'application/json'
            },
            body: JSON.stringify({
                model: 'command',
                prompt: prompt,
                max_tokens: 200,
                temperature: 0.7
            })
        });
        
        const data = await response.json();
        return data.generations[0].text;
    }

    // Option 4: Google Gemini (gratuit avec limitations)
    async tryGemini(prompt) {
        if (!this.config.gemini.apiKey) return null;
        
        const response = await fetch(
            `${this.config.gemini.endpoint}?key=${this.config.gemini.apiKey}`,
            {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify({
                    contents: [{
                        parts: [{
                            text: prompt
                        }]
                    }]
                })
            }
        );
        
        const data = await response.json();
        return data.candidates[0].content.parts[0].text;
    }

    // Option 5: OpenAI (payant mais excellent)
    async tryOpenAI(prompt) {
        if (!this.config.openai.apiKey) return null;
        
        const response = await fetch(this.config.openai.endpoint, {
            method: 'POST',
            headers: {
                'Authorization': `Bearer ${this.config.openai.apiKey}`,
                'Content-Type': 'application/json'
            },
            body: JSON.stringify({
                model: this.config.openai.model,
                messages: [
                    { role: 'system', content: 'Tu es OrgaGPT, un assistant de productivit√© expert.' },
                    { role: 'user', content: prompt }
                ],
                temperature: 0.7,
                max_tokens: 500
            })
        });
        
        const data = await response.json();
        return data.choices[0].message.content;
    }

    // Fallback intelligent avec analyse locale
    async getSmartFallback(message) {
        // Analyser l'intention avec des patterns plus sophistiqu√©s
        const intent = this.analyzeIntent(message);
        const context = this.buildContext();
        
        // G√©n√©rer une r√©ponse contextuelle
        return this.generateContextualResponse(intent, context);
    }

    analyzeIntent(message) {
        const lowerMessage = message.toLowerCase();
        
        // Patterns d'intention
        const intents = {
            askProductivity: /productivit√©|efficace|am√©liorer|optimiser/i,
            askPlanning: /planning|planifier|organiser|agenda/i,
            askEnergy: /√©nergie|fatigue|concentration|focus/i,
            askPriorities: /priorit√©|important|urgent|eisenhower/i,
            askStats: /statistique|rapport|analyse|performance/i,
            askHelp: /aide|comment|quoi faire|conseil/i,
            askMethods: /m√©thode|technique|pomodoro|gtd/i,
            askTime: /temps|heure|dur√©e|combien/i
        };
        
        for (const [intent, pattern] of Object.entries(intents)) {
            if (pattern.test(lowerMessage)) {
                return intent;
            }
        }
        
        return 'general';
    }

    generateContextualResponse(intent, context) {
        const responses = {
            askProductivity: () => {
                const score = Math.round((context.completedTasks / context.totalTasks) * 100) || 0;
                return `üìä Votre productivit√© actuelle est de **${score}%** avec ${context.completedTasks}/${context.totalTasks} t√¢ches compl√©t√©es.

D'apr√®s **McKinsey**, vous devriez consacrer 95% de votre temps √† vos 5 priorit√©s principales. Actuellement, vos priorit√©s sont : ${context.topPriorities.join(', ')}.

üí° **Recommandations personnalis√©es :**
${score < 50 ? '- Utilisez la technique Pomodoro pour augmenter votre focus' : '- Continuez sur cette lanc√©e !'}
${context.energyLevel === 'low' ? '- Votre √©nergie est faible, privil√©giez les t√¢ches administratives' : '- Profitez de votre √©nergie pour les t√¢ches complexes'}
${context.totalTasks > 10 ? '- Vous avez beaucoup de t√¢ches, utilisez la matrice d\'Eisenhower pour prioriser' : ''}

Voulez-vous que je vous aide √† optimiser votre planning ?`;
            },
            
            askEnergy: () => {
                const recommendations = {
                    high: 'üîã √ânergie haute d√©tect√©e ! C\'est le moment id√©al pour le travail profond et cr√©atif.',
                    medium: '‚ö° √ânergie moyenne : parfait pour les r√©unions et la communication.',
                    low: 'ü™´ √ânergie basse : concentrez-vous sur l\'administratif et la planification.'
                };
                
                return `${recommendations[context.energyLevel]}

Selon **KPMG**, aligner vos t√¢ches avec vos niveaux d'√©nergie peut augmenter votre productivit√© de 23%.

**Plan optimis√© pour votre niveau d'√©nergie :**
${this.generateEnergyBasedPlan(context.energyLevel, context.topPriorities)}

üí° Astuce : Prenez une pause de 5-10 minutes toutes les heures pour maintenir votre √©nergie.`;
            },
            
            askPriorities: () => {
                const urgentTasks = this.app.tasks.filter(t => t.quadrant === 1 && !t.completed);
                const importantTasks = this.app.tasks.filter(t => t.quadrant === 2 && !t.completed);
                
                return `üìã **Analyse de vos priorit√©s selon Eisenhower :**

üî¥ **Urgent & Important** (${urgentTasks.length} t√¢ches)
${urgentTasks.slice(0, 3).map(t => `- ${t.title}`).join('\n')}

üü¢ **Important, non urgent** (${importantTasks.length} t√¢ches)
${importantTasks.slice(0, 3).map(t => `- ${t.title}`).join('\n')}

D'apr√®s **Deloitte**, passer trop de temps dans le quadrant "Urgent" m√®ne au burnout. Visez 60% de votre temps dans le quadrant "Important, non urgent".

**Action recommand√©e :** ${urgentTasks.length > 3 ? 'D√©l√©guez certaines t√¢ches urgentes' : 'Planifiez du temps pour les t√¢ches importantes'}`;
            },
            
            default: () => {
                return `Je suis OrgaGPT, votre copilote productivit√© bas√© sur les meilleures pratiques des cabinets de conseil.

**Ce que je peux faire pour vous :**
üéØ Analyser et optimiser vos priorit√©s
üìä G√©n√©rer des rapports de productivit√©
‚è∞ Recommander les meilleures m√©thodes (Pomodoro, GTD, etc.)
üîã Adapter votre planning √† votre √©nergie
üìà Suivre vos progr√®s et sugg√©rer des am√©liorations

**Fait int√©ressant :** Vous avez d√©j√† compl√©t√© ${context.completedTasks} t√¢ches et accumul√© ${context.focusTime} de temps de focus !

Que souhaitez-vous am√©liorer aujourd'hui ?`;
            }
        };
        
        const responseFunc = responses[intent] || responses.default;
        return responseFunc();
    }

    generateEnergyBasedPlan(energyLevel, priorities) {
        const plans = {
            high: priorities.slice(0, 2).map(p => `- üß† ${p} (90 min de deep work)`).join('\n'),
            medium: priorities.slice(0, 2).map(p => `- üí¨ ${p} (45 min avec pauses)`).join('\n'),
            low: `- üìß Traiter les emails (30 min)\n- üìÖ Planifier demain (20 min)`
        };
        
        return plans[energyLevel] || plans.medium;
    }

    // Interface pour configurer l'IA
    addAISelector() {
        const aiConfig = document.createElement('div');
        aiConfig.className = 'ai-config-panel';
        aiConfig.innerHTML = `
            <div class="ai-config-header">
                <h3>‚öôÔ∏è Configuration IA</h3>
                <button class="btn btn--sm" onclick="realAI.toggleConfig()">Configurer</button>
            </div>
            <div class="ai-config-content" id="aiConfigContent" style="display: none;">
                <div class="ai-options">
                    <h4>Options gratuites recommand√©es :</h4>
                    
                    <div class="ai-option">
                        <h5>1. Ollama (100% local)</h5>
                        <p>Installez depuis <a href="https://ollama.ai" target="_blank">ollama.ai</a></p>
                        <button class="btn btn--sm" onclick="realAI.testOllama()">Tester Ollama</button>
                    </div>
                    
                    <div class="ai-option">
                        <h5>2. Hugging Face</h5>
                        <input type="text" id="hfApiKey" placeholder="Cl√© API Hugging Face">
                        <button class="btn btn--sm" onclick="realAI.saveHFKey()">Sauvegarder</button>
                        <small>Obtenez une cl√© gratuite sur <a href="https://huggingface.co" target="_blank">huggingface.co</a></small>
                    </div>
                    
                    <div class="ai-option">
                        <h5>3. Google Gemini</h5>
                        <input type="text" id="geminiApiKey" placeholder="Cl√© API Gemini">
                        <button class="btn btn--sm" onclick="realAI.saveGeminiKey()">Sauvegarder</button>
                        <small>Obtenez une cl√© gratuite sur <a href="https://makersuite.google.com" target="_blank">makersuite.google.com</a></small>
                    </div>
                    
                    <div class="ai-option">
                        <h5>4. Cohere</h5>
                        <input type="text" id="cohereApiKey" placeholder="Cl√© API Cohere">
                        <button class="btn btn--sm" onclick="realAI.saveCohereKey()">Sauvegarder</button>
                        <small>100 requ√™tes/min gratuites sur <a href="https://cohere.ai" target="_blank">cohere.ai</a></small>
                    </div>
                </div>
                
                <div class="ai-status" id="aiStatus">
                    <p>Status: <span id="aiStatusText">Non configur√©</span></p>
                </div>
            </div>
        `;
        
        // Ajouter √† la sidebar
        const sidebar = document.querySelector('.sidebar--right');
        if (sidebar) {
            sidebar.insertBefore(aiConfig, sidebar.firstChild);
        }
        
        // V√©rifier le status
        this.updateAIStatus();
    }

    toggleConfig() {
        const content = document.getElementById('aiConfigContent');
        if (content) {
            content.style.display = content.style.display === 'none' ? 'block' : 'none';
        }
    }

    async testOllama() {
        try {
            const response = await fetch('http://localhost:11434/api/generate', {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify({
                    model: 'gemma3:1b',
                    prompt: 'Test',
                    stream: false
                })
            });
            
            if (response.ok) {
                this.updateAIStatus('Ollama connect√© ‚úÖ');
                this.app.addAIMessage('üéâ Ollama est configur√© ! Je peux maintenant vous fournir des r√©ponses IA locales.');
            } else {
                throw new Error('Ollama non disponible');
            }
        } catch (e) {
            this.updateAIStatus('Ollama non d√©tect√© ‚ùå');
            alert('Ollama n\'est pas install√©. T√©l√©chargez-le depuis ollama.ai');
        }
    }

    saveHFKey() {
        const key = document.getElementById('hfApiKey').value;
        if (key) {
            this.config.huggingface.apiKey = key;
            this.saveConfig();
            this.updateAIStatus('Hugging Face configur√© ‚úÖ');
        }
    }

    saveGeminiKey() {
        const key = document.getElementById('geminiApiKey').value;
        if (key) {
            this.config.gemini.apiKey = key;
            this.saveConfig();
            this.updateAIStatus('Google Gemini configur√© ‚úÖ');
        }
    }

    saveCohereKey() {
        const key = document.getElementById('cohereApiKey').value;
        if (key) {
            this.config.cohere.apiKey = key;
            this.saveConfig();
            this.updateAIStatus('Cohere configur√© ‚úÖ');
        }
    }

    saveConfig() {
        // Sauvegarder les cl√©s de mani√®re s√©curis√©e (en production, utilisez un backend)
        const configToSave = {
            huggingface: { apiKey: this.config.huggingface.apiKey },
            gemini: { apiKey: this.config.gemini.apiKey },
            cohere: { apiKey: this.config.cohere.apiKey }
        };
        localStorage.setItem('orgagpt-ai-config', JSON.stringify(configToSave));
    }

    updateAIStatus(message) {
        const statusText = document.getElementById('aiStatusText');
        if (statusText) {
            if (message) {
                statusText.textContent = message;
            } else {
                // V√©rifier quelles IA sont disponibles
                const available = [];
                if (this.ollamaAvailable) available.push('Ollama');
                if (this.config.huggingface.apiKey) available.push('HuggingFace');
                if (this.config.gemini.apiKey) available.push('Gemini');
                if (this.config.cohere.apiKey) available.push('Cohere');
                
                statusText.textContent = available.length > 0 
                    ? `Actif: ${available.join(', ')}` 
                    : 'Non configur√©';
            }
        }
    }

    showTypingIndicator() {
        const chatMessages = document.getElementById('chatMessages');
        const indicator = document.createElement('div');
        indicator.className = 'typing-indicator';
        indicator.id = 'typingIndicator';
        indicator.innerHTML = `
            <div class="typing-dot"></div>
            <div class="typing-dot"></div>
            <div class="typing-dot"></div>
        `;
        chatMessages.appendChild(indicator);
        chatMessages.scrollTop = chatMessages.scrollHeight;
    }

    hideTypingIndicator() {
        const indicator = document.getElementById('typingIndicator');
        if (indicator) indicator.remove();
    }

    processAIActions(response) {
        // D√©tecter et proposer des actions bas√©es sur la r√©ponse
        if (response.includes('Pomodoro')) {
            this.suggestAction('D√©marrer une session Pomodoro', () => {
                this.app.startFocusSession();
            });
        }
        
        if (response.includes('Eisenhower')) {
            this.suggestAction('Voir la matrice d\'Eisenhower', () => {
                this.app.switchView('eisenhower');
            });
        }
        
        if (response.includes('rapport')) {
            this.suggestAction('G√©n√©rer un rapport d√©taill√©', () => {
                this.generateDetailedReport();
            });
        }
    }

    suggestAction(text, callback) {
        const suggestion = document.createElement('div');
        suggestion.className = 'action-suggestion fade-in';
        suggestion.innerHTML = `
            <span>üí° ${text}</span>
            <button class="btn btn--primary btn--sm">Faire maintenant</button>
        `;
        
        suggestion.querySelector('button').onclick = callback;
        document.getElementById('chatMessages').appendChild(suggestion);
    }

    async generateDetailedReport() {
        const context = this.buildContext();
        const prompt = `G√©n√®re un rapport de productivit√© d√©taill√© avec les donn√©es suivantes : ${JSON.stringify(context)}`;
        
        try {
            const report = await this.getAIResponse(prompt);
            this.showReportModal(report);
        } catch (e) {
            this.app.addAIMessage('üìä Je g√©n√®re votre rapport avec les donn√©es disponibles...');
            // G√©n√©rer un rapport local si l'IA √©choue
            this.showLocalReport(context);
        }
    }

    showReportModal(content) {
        const modal = document.createElement('div');
        modal.className = 'modal active';
        modal.innerHTML = `
            <div class="modal-content modal-large">
                <div class="modal-header">
                    <h3>üìä Rapport de Productivit√© IA</h3>
                    <button class="modal-close" onclick="this.closest('.modal').remove()">&times;</button>
                </div>
                <div class="modal-body">
                    <div class="ai-report">${content.replace(/\n/g, '<br>')}</div>
                </div>
            </div>
        `;
        document.body.appendChild(modal);
    }

    showLocalReport(context) {
        const report = `
            <h2>Rapport de Productivit√© - ${new Date().toLocaleDateString('fr-FR')}</h2>
            
            <h3>üìà R√©sum√© Ex√©cutif</h3>
            <p>T√¢ches compl√©t√©es : ${context.completedTasks}/${context.totalTasks} (${Math.round((context.completedTasks/context.totalTasks)*100)}%)</p>
            <p>Temps de focus : ${context.focusTime}</p>
            <p>Sessions Pomodoro : ${context.pomodoroCount}</p>
            
            <h3>üéØ Priorit√©s Actuelles</h3>
            <ul>${context.topPriorities.map(p => `<li>${p}</li>`).join('')}</ul>
            
            <h3>üí° Recommandations</h3>
            <p>Bas√© sur votre niveau d'√©nergie ${context.energyLevel}, concentrez-vous sur les t√¢ches ${context.energyLevel === 'high' ? 'complexes et cr√©atives' : 'administratives'}.</p>
        `;
        
        this.showReportModal(report);
    }
}

// Styles pour la configuration IA
const aiStyles = `
<style>
.ai-config-panel {
    background: var(--color-background);
    border-radius: var(--radius-base);
    padding: var(--space-16);
    margin-bottom: var(--space-16);
    border: 1px solid var(--color-border);
}

.ai-config-header {
    display: flex;
    justify-content: space-between;
    align-items: center;
    margin-bottom: var(--space-16);
}

.ai-option {
    background: var(--color-surface);
    padding: var(--space-12);
    border-radius: var(--radius-sm);
    margin-bottom: var(--space-12);
}

.ai-option h5 {
    margin: 0 0 var(--space-8) 0;
    color: var(--color-primary);
}

.ai-option input {
    width: 100%;
    margin-bottom: var(--space-8);
}

.ai-option small {
    display: block;
    margin-top: var(--space-4);
    color: var(--color-text-secondary);
}

.ai-status {
    margin-top: var(--space-16);
    padding: var(--space-12);
    background: var(--color-secondary);
    border-radius: var(--radius-sm);
    text-align: center;
}

.action-suggestion {
    background: linear-gradient(135deg, var(--color-primary), var(--color-primary-hover));
    color: white;
    padding: var(--space-12);
    border-radius: var(--radius-base);
    margin: var(--space-12) 0;
    display: flex;
    justify-content: space-between;
    align-items: center;
}

.ai-report {
    line-height: 1.6;
    color: var(--color-text);
}

.ai-report h2, .ai-report h3 {
    margin-top: var(--space-24);
    margin-bottom: var(--space-12);
    color: var(--color-primary);
}

.ai-report ul {
    padding-left: var(--space-24);
}
</style>
`;

document.head.insertAdjacentHTML('beforeend', aiStyles);

// Auto-initialisation
document.addEventListener('DOMContentLoaded', () => {
    // Attendre que l'app originale soit compl√®tement initialis√©e
    setTimeout(() => {
        if (window.orgaGPT) {
            console.log('ü§ñ Initialisation de RealAIOrgaGPT...');
            window.realAI = new RealAIOrgaGPT(window.orgaGPT);
            
            // Ajouter un indicateur visuel que l'IA est active
            const aiTitle = document.querySelector('.sidebar__section h3:contains("ü§ñ Copilote IA")');
            if (aiTitle) {
                aiTitle.innerHTML = 'ü§ñ Copilote IA <span style="color: green; font-size: 0.8em;">(Ollama actif)</span>';
            }
            
            // Forcer le remplacement de la m√©thode sendChatMessage
            const originalSendChatMessage = window.orgaGPT.sendChatMessage;
            window.orgaGPT.sendChatMessage = async function() {
                const input = document.getElementById('chatInput');
                const message = input.value.trim();
                
                if (!message || !input) return;

                this.addUserMessage(message);
                input.value = '';

                // Afficher l'indicateur de chargement
                const chatMessages = document.getElementById('chatMessages');
                const loadingDiv = document.createElement('div');
                loadingDiv.className = 'ai-message typing-indicator';
                loadingDiv.innerHTML = '<span>.</span><span>.</span><span>.</span>';
                chatMessages.appendChild(loadingDiv);

                try {
                    // Obtenir une vraie r√©ponse IA via Ollama
                    const response = await fetch('http://localhost:11434/api/generate', {
                        method: 'POST',
                        headers: { 'Content-Type': 'application/json' },
                        body: JSON.stringify({
                            model: 'gemma3:1b',
                            prompt: `Tu es OrgaGPT, un assistant de productivit√© expert. R√©ponds √† cette question: ${message}`,
                            stream: false
                        })
                    });
                    
                    const data = await response.json();
                    // Supprimer l'indicateur de chargement
                    loadingDiv.remove();
                    
                    // Afficher la r√©ponse
                    this.addAIMessage(data.response);
                    console.log('ü§ñ R√©ponse IA re√ßue via Ollama');
                    
                } catch (error) {
                    console.error('Erreur avec Ollama:', error);
                    loadingDiv.remove();
                    
                    // Fallback vers la m√©thode originale
                    const fallbackResponse = this.generateAIResponse(message);
                    this.addAIMessage(fallbackResponse + '\n\n[Note: R√©ponse g√©n√©r√©e localement car Ollama n\'est pas disponible]');
                }
            };
            
            console.log('‚úÖ Int√©gration IA activ√©e avec succ√®s!');
        } else {
            console.error('‚ùå Impossible d\'initialiser RealAIOrgaGPT: orgaGPT non trouv√©');
        }
    }, 500); // Augmenter le d√©lai pour s'assurer que tout est charg√©
});

// Ajouter des styles pour l'indicateur de chargement
const typingStyles = `
<style>
.typing-indicator {
    display: flex;
    align-items: center;
    column-gap: 4px;
}

.typing-indicator span {
    animation: blink 1s infinite;
    font-size: 20px;
}

.typing-indicator span:nth-child(2) {
    animation-delay: 0.2s;
}

.typing-indicator span:nth-child(3) {
    animation-delay: 0.4s;
}

@keyframes blink {
    0% { opacity: 0.2; }
    20% { opacity: 1; }
    100% { opacity: 0.2; }
}
</style>
`;

document.head.insertAdjacentHTML('beforeend', typingStyles);